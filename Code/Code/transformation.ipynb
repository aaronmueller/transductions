{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Sequence to Sequence Models\n",
    "LING 380/780 -- Neural Network Models of Linguistic Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the necessary pytorch packages, along with the seq2seq model defintion and training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import model\n",
    "import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the functions that will create and load the synthetic datasets using PCFGs defined in *grammars.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import create_file\n",
    "from data_prep import load_and_prepare_dataset\n",
    "\n",
    "from grammars import pcfg_agreement_pp, pcfg_agreement_pp_ambig, pcfg_agreement_pp_unambig\n",
    "from grammars import gen_reinflection_example, gen_pres_reinflection_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these functions to generate datasets (which will be stored in the *data* and *cache* subdirectories), and then use *load_and_prepare_dataset* to create training, validation and testing sets, along with text objects for the source (input) and target (output), which will be used for their vocabulary objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file('reinflection_pp',pcfg_agreement_pp_ambig,gen_reinflection_example,5000)\n",
    "create_file('reinflection_pp_test',pcfg_agreement_pp_unambig,gen_pres_reinflection_example,100)\n",
    "\n",
    "train_iter, val_iter, test_iter, src_text, trg_text = load_and_prepare_dataset('reinflection_pp', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some hyperparameters and create the loss, the network and optimizer objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 128\n",
    "ATTENTION = 'Null'\n",
    "\n",
    "PAD_IDX = trg_text.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "net = model.Seq2Seq(src_text, EMBEDDING_SIZE, HIDDEN_SIZE, trg_text, attention=ATTENTION)\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the set of words that will be used to compute accuracy (if the value of the *eval_words* argument of *train* is not specified, accuracy will be computed for all words in the target).  Here, since we are interested in assessing accuracy in inflecting verbs, we consider only present tense verbs, in both singular and plural forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_verbs = ['laughs','dances','hopes','burps', 'coughs', 'dies', 'laugh', 'dance', 'hope', 'burp', 'cough', 'die']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "train.train(net, train_iter, val_iter, test_iter, optimizer, criterion, short_train=False, n_epochs=N_EPOCHS, eval_words = eval_verbs, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load evaluation functions that provide an interface for the translating sentences and batches, and plotting a heatmap for attention weights for each word in an output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import translate_batch, translate, plot_from_batch, plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try translating some sentences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(net, 'the gentle badger coughed', 'past' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(net, 'the gentle badger coughed', 'past' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(net, 'with the gentle kindly dogs the humble badger danced', 'pres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a test batch with a given target length to be used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_target_length = 10\n",
    "\n",
    "for i in test_iter:\n",
    "    if i.trg.shape[0]==desired_target_length:\n",
    "        sample_test_batch = i\n",
    "        continue\n",
    "\n",
    "print(sample_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_batch(net, sample_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_from_batch(net, sample_test_batch, 0) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda453541678ccb41069ce493c91d802997"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}